{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5173c23",
   "metadata": {},
   "source": [
    "# Demo (Assessing GCG Suffixes' Hijacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9465b2e2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc19016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"svg\"  # 'html'\n",
    "pio.templates.default = \"plotly_white\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b89255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.interp.utils import load_model\n",
    "from src.evaluate.utils import load_data\n",
    "\n",
    "model_name = \"google/gemma-2-2b-it\"\n",
    "# model_name = \"qwen/qwen2.5-1.5b-instruct\"\n",
    "# model_name = \"meta-llama/llama-3-8b-instruct\"\n",
    "\n",
    "\n",
    "data_df = load_data(model_name=model_name)\n",
    "\n",
    "model = load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24b8b95",
   "metadata": {},
   "source": [
    "## Load GCG Suffixes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f13e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\">> dataset size: {data_df.shape[0]} rows.\")\n",
    "print(f\">> {data_df.suffix_id.nunique()} different GCG suffixes, evaluated on {data_df.message_id.nunique()} messages.\")\n",
    "\n",
    "univ_scores = data_df.groupby('suffix_id').agg({'univ_score': 'first'}).sort_values(by='univ_score', ascending=False).reset_index()\n",
    "# TODO fix\n",
    "# px.bar(\n",
    "#     univ_scores,\n",
    "#     x='univ_score',\n",
    "#     title=f\"GCG suffixes' Universal Scores ({model_name})\",\n",
    "#     labels={'universal_score': 'Universal Score'},\n",
    "# ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f49ee6",
   "metadata": {},
   "source": [
    "## Extract Transformed Vectors\n",
    "Extracting the fine-grained components of the attention calculation, to inspect the information flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424c8bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minterp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_toks\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m input_ids, _ = to_toks(\u001b[33m\"\u001b[39m\u001b[33mWrite a parody song based on The Beatles\u001b[39m\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mStrawberry Fields\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mmodel\u001b[49m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(model.tokenizer.decode(input_ids))\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from src.interp.utils import to_toks\n",
    "\n",
    "\n",
    "toks, _ = to_toks(\"Write a parody song based on The Beatles' 'Strawberry Fields'\", model).squeeze(0)\n",
    "print(model.tokenizer.decode(toks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59416412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporarily enable fine-grained attention hooks (this is memory consuming, but required for our analysis)\n",
    "model.set_use_attn_fine_grained(True)  \n",
    "\n",
    "_, cache = model.run_with_cache(toks)\n",
    "cache.to('cpu')\n",
    "model.set_use_attn_fine_grained(False)\n",
    "\n",
    "# The decompoased attetnion outputs (=transformed vectors) tensor:\n",
    "cache['Y'].shape  # (n_layers, n_head, dst_seq, src_seq, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d36da7",
   "metadata": {},
   "source": [
    "### Dominance score\n",
    "\n",
    "Quantifying the dominance score across the layers (reproducing Fig. 5 in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d69bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dominance_area_plot(dom_scores, name=None):\n",
    "    ## build df:\n",
    "    df = []\n",
    "    for src_name, values in dom_scores.items():\n",
    "        for layer, val in enumerate(values):\n",
    "            df.append({\n",
    "                'src_name': src_name,\n",
    "                'layer': layer,\n",
    "                'val': val.item()\n",
    "            })\n",
    "    df = pd.DataFrame(df)\n",
    "\n",
    "    colors = {\n",
    "        'bos': '#A9A9A9',       # Dark grey\n",
    "        'chat_pre': '#D3D3D3',  # Light grey\n",
    "        'instr': '#4B77BE',     # Dark green\n",
    "        'adv': \"#E8362D\",           # Dark red\n",
    "        'chat[:-1]': '#FFA500',      # Orange\n",
    "        'chat[-1]': '#FFB84D'       # Light orange-yellow (subtler)\n",
    "    }\n",
    "\n",
    "    px.area(\n",
    "        df,\n",
    "        x='layer',\n",
    "        y='val',\n",
    "        color='src_name',\n",
    "        labels={'val': 'Dominance Score', 'layer': 'Layer', 'src_name': 'Source Subseq.'},\n",
    "        color_discrete_map=colors,\n",
    "        width=500, height=350,\n",
    "        template='plotly_white',\n",
    "        title=f\"Dominance Scores to 'chat[-1]'\" + (f' ({name})' if name else ''),\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9d17f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from src.interp.dominance_tools import get_adv_hijack_score\n",
    "import src.interp.dominance_tools as dominance_tools\n",
    "from src.interp.dominance_tools import get_dominance_scores\n",
    "\n",
    "message = data_df[data_df.message_id == 619].iloc[0].message_str\n",
    "suffix_rand = data_df[data_df.suffix_category == 'init'].suffix_str.iloc[0]\n",
    "suffix_gcg = data_df[data_df.suffix_rank == 0].suffix_str.iloc[0]\n",
    "\n",
    "for suffix_name, suffix_str in [('random suffix', suffix_rand), ('GCG suffix', suffix_gcg)]:\n",
    "    dom_scores = get_dominance_scores( # wraps the extraction of 'Y' and calculation of dominance\n",
    "        model,\n",
    "        message, suffix_str,\n",
    "        dst_slc_name = 'chat[-1]',\n",
    "        hijacking_metric ='Y@attn',  # 'Y@resid', 'Y@attn', 'X@WVO@attn', 'Y@dcmp_resid', 'Y@dir\n",
    "        hijacking_metric_flavor = 'sum',  # 'sum', 'sum-top0.1'\n",
    "    )\n",
    "\n",
    "    show_dominance_area_plot(dom_scores, name=suffix_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
